{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "principal_components_analysis.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM3WnXtss2/rPYnCzxiABKN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Priyo-prog/Machine-Learning/blob/main/Principal%20Component%20Analysis/principal_components_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Principal Component Analysis**\n",
        "\n",
        "* Create some gene data\n",
        "* Use **PCA()** function from sklearn to do PCA\n",
        "* Determine how much variation each principal components accounts for\n",
        "* Draw a fancy PCA graph using matplotlib\n",
        "* Examin the loading scores to determine what variables have the largest effect on the graph."
      ],
      "metadata": {
        "id": "oYLCuxBlvSBt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import important packages"
      ],
      "metadata": {
        "id": "gnBT0h9Gur_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random as rd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "lkZlNJNUuoV0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate sample dataset\n",
        "\n",
        "* The first thing we do is generate an array of 100 gene names.\n",
        "* Since this is just an example we name them as \"gene1\", \"gene2\" etc."
      ],
      "metadata": {
        "id": "vnOFZczIvAFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genes = ['gene' + str(i) for i in range(1,101)]"
      ],
      "metadata": {
        "id": "eAt3dJSZwfQh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Now we create arrays of sample names.\n",
        "* We have 5 \"wild type\" or \"wt\" samples\n",
        "* 5 \"knock out\" or \"ko\" samples"
      ],
      "metadata": {
        "id": "MyFTiYpAb0cg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wt = ['wt' + str(i) for i in range(1,6)]\n",
        "ko = ['ko' + str(i) for i in range(1,6)]"
      ],
      "metadata": {
        "id": "wRM8MGwUcTaA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we create a pandas dataframe to store the made up data"
      ],
      "metadata": {
        "id": "UtxNYg7tdSR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The \"stars\" unpack the \"wt\" and \"ko\" arrays so that column names are single array\n",
        "data = pd.DataFrame(columns=[*wt, *ko], index=genes)"
      ],
      "metadata": {
        "id": "l2qYjLzkdfQT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally creating the random data.\n",
        "\n",
        "* For each gene in the \"index\", we create 5 values for \"wt\" samples and 5 values for \"ko\" samples\n",
        "* The made up datacomes from two possion distribution: one for wt samples and one for ko samples"
      ],
      "metadata": {
        "id": "qig_VbsBeNh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for gene in data.index:\n",
        "  data.loc[gene, 'wt1':'wt5'] = np.random.poisson(lam=rd.randrange(10,1000), size=5)\n",
        "  data.loc[gene, 'ko1':'ko5'] = np.random.poisson(lam=rd.randrange(10,1000), size=5)"
      ],
      "metadata": {
        "id": "XhGwW5LdChfv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(), data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XklV5qjnF_fM",
        "outputId": "f6743e9b-6535-4f6d-f4af-1e085672642f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(       wt1  wt2  wt3  wt4  wt5  ko1  ko2  ko3  ko4  ko5\n",
              " gene1   34   39   29   37   37   10   18   15   15   13\n",
              " gene2  562  501  532  550  534  322  312  292  325  309\n",
              " gene3   27   29   33   32   30  796  766  753  778  798\n",
              " gene4  261  235  239  248  253  910  860  827  913  821\n",
              " gene5  302  309  306  272  279  745  754  735  713  771, (100, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing the data\n",
        "\n",
        "* Before we do PCA we have to centre and scale the data\n",
        "* After centering, the average value for each gene will be 0 and after scaling the standard deviation for the values for each gene will be 1\n",
        "* We are transposing the data, the scale function expects the samples to be rows instead of columns.\n",
        "* We can also use StandardScaler().fit_transform() as well"
      ],
      "metadata": {
        "id": "dNTn-mmtGio2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_data = preprocessing.scale(data.T)\n",
        "\n",
        "# Now we are good to go ahead with PCA, create an object of PCA class\n"
      ],
      "metadata": {
        "id": "dnwlWCfSHbJm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}